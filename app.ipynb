{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqNq6BE2qSpj",
        "outputId": "1a1d3b5e-79c6-4269-b878-347f351bfdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error making API call to gpt-4: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Error generating response from Domain A expert.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from anthropic import Anthropic\n",
        "\n",
        "# Set up API keys\n",
        "openai.api_key = os.environ.get(\"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\")\n",
        "anthropic_api_key = os.environ.get(\"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\")\n",
        "\n",
        "# Initialize Anthropic client\n",
        "anthropic = Anthropic(api_key=anthropic_api_key)\n",
        "\n",
        "def make_api_call(model_name, prompt, max_tokens):\n",
        "    try:\n",
        "        if model_name == \"gpt-4\":\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        elif model_name == \"claude-2\":\n",
        "            response = anthropic.completions.create(\n",
        "                model=\"claude-2\",\n",
        "                prompt=prompt,\n",
        "                max_tokens_to_sample=max_tokens,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            return response.completion\n",
        "        else:\n",
        "            return \"Invalid model selected.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error making API call to {model_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def generate_collaborative_response(prompt):\n",
        "    domain_a_prompt = f\"Human: As an expert in Domain A, respond to this prompt: {prompt}\\n\\nAssistant:\"\n",
        "    domain_a_response = make_api_call(\"gpt-4\", domain_a_prompt, 100)\n",
        "    if domain_a_response is None:\n",
        "        return \"Error generating response from Domain A expert.\"\n",
        "\n",
        "    domain_b_prompt = f\"Human: As an expert in Domain B, provide additional information or perspective on this topic: {prompt}\\n\\nAssistant:\"\n",
        "    domain_b_response = make_api_call(\"claude-2\", domain_b_prompt, 100)\n",
        "    if domain_b_response is None:\n",
        "        return \"Error generating response from Domain B expert.\"\n",
        "\n",
        "    aggregator_prompt = f\"\"\"Human: Combine and synthesize the following expert responses to answer the original prompt: \"{prompt}\"\n",
        "\n",
        "Domain A Expert: {domain_a_response}\n",
        "Domain B Expert: {domain_b_response}\n",
        "\n",
        "Assistant: Provide a comprehensive and balanced answer based on both experts' input.\n",
        "\"\"\"\n",
        "    final_response = make_api_call(\"gpt-4\", aggregator_prompt, 200)\n",
        "    return final_response\n",
        "\n",
        "def main():\n",
        "    prompt = \"What is the capital of France?\"\n",
        "    response = generate_collaborative_response(prompt)\n",
        "    print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}